# React + TypeScript + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

# AI Presentation Professor 🎓

An intelligent presentation assistant powered by Google Gemini AI that provides real-time explanations of your slides with text-to-speech narration and multi-language support.

![AI Presentation Professor](https://img.shields.io/badge/AI-Powered-blue) ![React](https://img.shields.io/badge/React-19-61DAFB) ![TypeScript](https://img.shields.io/badge/TypeScript-Ready-blue) ![Gemini](https://img.shields.io/badge/Google-Gemini-yellow)

## ✨ Features

### 🧠 **AI-Powered Slide Analysis**
- **Real-time slide detection** using advanced image comparison algorithms
- **Intelligent explanations** generated by Google Gemini 2.5 Flash
- **Contextual understanding** that builds upon previous slides for coherent lectures
- **Automatic slide change detection** with configurable similarity thresholds

### 🗣️ **Text-to-Speech Integration**
- **Automatic narration** of AI-generated explanations
- **Natural voice synthesis** using Web Speech API
- **Mute/unmute controls** with persistent settings
- **Speaking status indicators** for better user experience

### 🌍 **Multi-Language Support**
- **English explanations** with professional academic tone
- **Indonesian (Bahasa Indonesia)** explanations with localized content
- **Dynamic language switching** during presentations
- **Language-specific system prompts** for culturally appropriate responses

### 🎨 **Modern User Interface**
- **Dark theme** design optimized for presentations
- **Responsive layout** that works on desktop and mobile
- **Real-time status indicators** for processing and speaking states
- **Smooth transitions** and hover effects for better UX

### 📊 **Smart Slide Processing**
- **Similarity threshold detection** (97% default) to avoid duplicate processing
- **Minimum processing intervals** (5 seconds) to prevent overprocessing
- **Canvas-based image analysis** for efficient performance
- **Background processing** that doesn't block the UI

## 🚀 Getting Started

### Prerequisites

- **Node.js** (v18 or higher)
- **Modern web browser** with screen sharing support (Chrome, Firefox, Safari, Edge)
- **Google Gemini API key** ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd professorgemini
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   
   Create a `.env` file in the root directory:
   ```env
   VITE_API_KEY=your_google_gemini_api_key_here
   ```

4. **Start development server**
   ```bash
   npm run dev
   ```

5. **Open your browser**
   
   Navigate to `http://localhost:5173`

## 🎮 How to Use

### Step 1: Setup
1. Open the application in your web browser
2. Ensure your Gemini API key is properly configured
3. Grant screen sharing permissions when prompted

### Step 2: Start Presenting
1. Click **"Start Presenting"** button
2. Select your presentation window or entire screen
3. Wait for the video preview to appear

### Step 3: Configure Settings
- **Language Toggle**: Switch between English (EN) and Indonesian (ID)
- **Audio Control**: Use the speaker icon to mute/unmute narration
- **Processing Status**: Monitor AI analysis progress in real-time

### Step 4: Present!
- Navigate through your slides normally
- AI will automatically detect new slides and provide explanations
- Explanations appear in the right panel with timestamps
- Text-to-speech reads explanations aloud (if not muted)

### Step 5: Stop Presenting
- Click **"Stop Presenting"** to end the session
- All data is cleared and resources are released

## ⚙️ Configuration

### Slide Detection Settings

You can adjust these constants in `App.tsx`:

```typescript
const SLIDE_CHECK_INTERVAL = 300;        // Check for slides every 300ms
const SIMILARITY_THRESHOLD = 0.97;       // 97% similarity threshold
const MIN_PROCESSING_INTERVAL = 5000;    // Wait 5 seconds between processing
```

### AI Behavior

The system prompts can be customized in `geminiService.ts`:

- **English prompt**: Professional university professor tone
- **Indonesian prompt**: Culturally appropriate academic language
- **Response format**: Plain text without markdown formatting

## 🏗️ Architecture

### Frontend Stack
- **React 19** with functional components and hooks
- **TypeScript** for type safety and better development experience
- **Vite** for fast development and optimized builds
- **TailwindCSS** for responsive, utility-first styling

### Core Components

```
src/
├── App.tsx              # Main application component
├── components/
│   └── icons.tsx        # SVG icon components
├── services/
│   ├── geminiService.ts # Google Gemini AI integration
│   └── ttsService.ts    # Text-to-speech functionality
└── types.ts             # TypeScript type definitions
```

### Key Technologies

- **Google Gemini API** (`@google/genai`) for AI explanations
- **Web Speech API** for text-to-speech functionality
- **Screen Capture API** for slide detection
- **Canvas API** for image processing and comparison

## 🔧 API Reference

### Gemini Service

```typescript
// Initialize AI chat
const chat = initializeChat();

// Generate slide explanation
const explanation = await explainSlide(
  base64Image: string,
  language: 'english' | 'indonesian'
);
```

### TTS Service

```typescript
// Speak text with callback
tts.speak(text: string, onEnd: () => void);

// Cancel current speech
tts.cancel();
```

## 📱 Browser Compatibility

| Browser | Screen Sharing | Text-to-Speech | Status |
|---------|---------------|----------------|--------|
| Chrome 88+ | ✅ | ✅ | Fully Supported |
| Firefox 66+ | ✅ | ✅ | Fully Supported |
| Safari 13+ | ✅ | ✅ | Fully Supported |
| Edge 88+ | ✅ | ✅ | Fully Supported |

## 🔒 Privacy & Security

- **Local Processing**: All image analysis happens in your browser
- **API Communication**: Only base64 images are sent to Google Gemini
- **No Data Storage**: No slide content is permanently stored
- **Secure Connections**: HTTPS required for screen sharing in production

## 🛠️ Development

### Available Scripts

```bash
npm run dev      # Start development server
npm run build    # Build for production
npm run preview  # Preview production build
npm run lint     # Run ESLint
```

### Project Structure

```
├── public/           # Static assets
├── src/
│   ├── components/   # React components
│   ├── services/     # API and utility services
│   ├── types.ts      # TypeScript definitions
│   ├── App.tsx       # Main application
│   └── main.tsx      # Application entry point
├── index.html        # HTML template
├── package.json      # Dependencies and scripts
├── tsconfig.json     # TypeScript configuration
├── vite.config.ts    # Vite configuration
└── tailwind.config.js # TailwindCSS configuration
```

## 🚀 Deployment

### Build for Production

```bash
npm run build
```

### Deploy to Vercel/Netlify

1. Connect your repository to your deployment platform
2. Set environment variable: `VITE_API_KEY`
3. Build command: `npm run build`
4. Output directory: `dist`

### Self-Hosting

```bash
npm run build
npx serve dist
```

## 🐛 Troubleshooting

### Common Issues

**Screen sharing not working**
- Ensure HTTPS in production
- Check browser permissions
- Try refreshing and starting again

**AI explanations not generating**
- Verify API key is correct
- Check console for error messages
- Ensure internet connection is stable

**Text-to-speech not working**
- Check browser compatibility
- Verify audio permissions
- Ensure volume is not muted

**Performance issues**
- Adjust `SLIDE_CHECK_INTERVAL` for slower checking
- Increase `MIN_PROCESSING_INTERVAL` to reduce API calls
- Lower `SIMILARITY_THRESHOLD` for more sensitive detection